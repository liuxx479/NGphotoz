{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/liuxx479/NGphotoz/blob/master/prep_mass_production.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ak9qWKy8pIbN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pylab import *\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import uniform\n",
    "from astropy.io import fits\n",
    "from astropy import units as u\n",
    "import os\n",
    "sys.modules[\"mpi4py\"] = None\n",
    "from lenstools import ConvergenceMap\n",
    "from IPython.display import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLKpb6dHpOLY"
   },
   "source": [
    "### goals of this notebook\n",
    "##### 1) compute the nubmer density per z bin, using the fiducial photo-z (sigma_z=0, or step function was used)\n",
    "##### 2) add noise as GRF to each redshift\n",
    "##### 3) smooth the maps\n",
    "##### 4) define the bin edges\n",
    "##### 5) compute peaks, minima, PDF, MFs, moments\n",
    "##### 6) turn this into a python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git add prep_map_stats.ipynb; git commit -m 'verified sigma_kappa = sqrt(2) sigma_e '; git push\n",
    "!git add map_stats.py; git commit -m 'map_stats.py test pass; ready for mass production'; git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "pF66fYtqp7ar",
    "outputId": "a28c8a3d-c47f-4d0e-9f78-4d50a8f09af2"
   },
   "outputs": [],
   "source": [
    "##### number density per redshift bins\n",
    "def Pz_norm(zp_support, pz):\n",
    "  return pz/np.trapz(pz, zp_support)\n",
    "\n",
    "def Pz_norm_tomo(zp_support, pz):\n",
    "  return array([Pz_norm(zp_support, ipz) for ipz in pz])\n",
    "\n",
    "zarr=np.linspace(0,4, 501)\n",
    "delta_z=0.5\n",
    "\n",
    "tomo_centers=np.arange(0.5, 3, delta_z)\n",
    "tomo_widths=np.ones(5)*delta_z\n",
    "tomo_edges = np.array([tomo_centers-delta_z/2, tomo_centers+delta_z/2]).T\n",
    "\n",
    "z0_SRD, alpha_SRD = 0.11, 0.68\n",
    "Pz_SRD_unnorm = lambda z: z**2 * exp(-(z/z0_SRD)**alpha_SRD)\n",
    "Pz_SRD_norm = lambda z: Pz_norm(z, Pz_SRD_unnorm(z))\n",
    "\n",
    "plot(zarr, Pz_SRD_norm(zarr), lw=2, label='LSST gold (SRD2018 Y10 p53)')\n",
    "xlabel('z')\n",
    "ylabel('Pz')\n",
    "legend()\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "no8Frqmiqh83"
   },
   "outputs": [],
   "source": [
    "############ fiducial model: pz_true.txt \n",
    "### zbias=0, sigma_z=0, outlier=0; it should have sharp cut off at the bin edges ([0.25, 0.75], [0.75, 1.25]...)\n",
    "####### LSST SRD Y10 numbers page 53\n",
    "######## SRD: https://arxiv.org/abs/1809.01669\n",
    "## neff: (z0, α) = (0.13, 0.78) for Y1 and (0.11, 0.68) for Y10\n",
    "## neff = 10 and 27 arcmin−2 as the lensing neff in Y1 and Y10\n",
    "## however, according to the original Chang 2013 paper, unmasked neff=37\n",
    "sigma_e = 0.26 ## per component, do I need a sqrt(2) to get both components? (I didn't do this in 2014..)\n",
    "neff = 37 ## chang+2013 n=46, for fiducial case\n",
    "#ngal = 46\n",
    "ngal = neff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) compute the nubmer density per z bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngal_tomo = np.zeros(5)\n",
    "Pz_norm_factor = np.trapz(Pz_SRD_unnorm(zarr),zarr)\n",
    "print (Pz_norm_factor)\n",
    "\n",
    "for i in range(5):\n",
    "    iz0,iz1=tomo_edges[i]\n",
    "    izarr=zarr[where((zarr>iz0)&(zarr<iz1))]\n",
    "    ngal_tomo[i]= ngal * np.trapz(Pz_SRD_unnorm(izarr), izarr) / Pz_norm_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('number of galaxies per redshift bin \\n(ngal=%i, %s galaxies in 5 bins):'%(ngal, sum(ngal_tomo)))\n",
    "for i in range(5):\n",
    "    print ('z=%s, ngal=%.2f /arcmin^2'%(tomo_edges[i], ngal_tomo[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) add noise as GRF to each redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### get a set of 5 test maps\n",
    "#test_dir = '/global/cscratch1/sd/jialiu/desc-sprint-raytracing/Cosmo_maps/06_f/'\n",
    "# std: [0.007314169, 0.019146424, 0.031151935, 0.041499652, 0.050280314]\n",
    "\n",
    "##### change to fiducial model, so I can get the std for the maps\n",
    "test_dir = '/global/cscratch1/sd/jialiu/desc-sprint-raytracing/Cosmo_maps/fid_f/'\n",
    "os.listdir(test_dir)[:10]\n",
    "fnames = [test_dir+'kappa_LSST-SRD_tomo%i_cone1.fits'%(i) for i in range(1,6)]\n",
    "test_maps = array([fits.open(ifn)[0].data for ifn in fnames])\n",
    "istds = [std(it) for it in test_maps]\n",
    "print (istds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### plot original kappa maps\n",
    "figure(figsize=(16,2))\n",
    "for i in range(5):\n",
    "    subplot(1,5,i+1)\n",
    "    istd=istds[i]\n",
    "    imshow(test_maps[i], vmin=-3*istd, vmax=3*istd, origin='lower', extent=[0,10,0,10])\n",
    "    title('noiseless z=%.1f'%(tomo_centers[i]))\n",
    "    colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### white noise maps for shape noise\n",
    "map_side_deg = 10*u.degree\n",
    "pixel_angular_side = map_side_deg / test_maps[0].shape[0]\n",
    "\n",
    "sigma_pix_arr =[ (sigma_e / (pixel_angular_side * sqrt(ingal / u.arcmin**2))).decompose().value\n",
    "                for ingal in ngal_tomo]\n",
    "\n",
    "print (map_side_deg, test_maps[0].shape[0])\n",
    "print (pixel_angular_side.to (u.arcmin))\n",
    "print (sigma_pix_arr)\n",
    "\n",
    "np.random.seed(2)\n",
    "noise_maps = [np.random.normal(loc=0.0, scale=sigma_pix_arr[i], size=test_maps[0].shape) \n",
    "              for i in range(5)]\n",
    "\n",
    "# #Generate shape noise\n",
    "#sigma = ((0.15 + 0.035*z) / (pixel_angular_side * np.sqrt(ngal))).decompose().value\n",
    "# np.random.seed(seed)\n",
    "# noise_map = np.random.normal(loc=0.0,scale=sigma,size=self.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## turn it into convergencemap instance\n",
    "conv_noiseless_maps = [ConvergenceMap(data=test_maps[i], angle=map_side_deg) for i in range(5)]\n",
    "conv_maps = [ConvergenceMap(data=test_maps[i]+noise_maps[i], angle=map_side_deg) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "istds_noisy = [conv_maps[i].std() for i in range(5)]\n",
    "print (istds_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(16,2))\n",
    "for i in range(5):\n",
    "    subplot(1,5,i+1)\n",
    "    istd=istds_noisy[i]\n",
    "    imshow(conv_maps[i].data, vmin=-3*istd, vmax=3*istd, origin='lower', extent=[0,10,0,10])\n",
    "    title('z=%.1f \\n ngal=%.2f'%(tomo_centers[i], ngal_tomo[i]))\n",
    "    colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) smooth the maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_g = 5 #arcmin\n",
    "smoothed_conv_maps= [conv_maps[i].smooth(theta_g*u.arcmin) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "istds_smoothed = [smoothed_conv_maps[i].std() for i in range(5)]\n",
    "print (istds_smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(16,2))\n",
    "for i in range(5):\n",
    "    subplot(1,5,i+1)\n",
    "    istd=istds_smoothed[i]\n",
    "    imshow(smoothed_conv_maps[i].data, vmin=-3*istd, vmax=3*istd, origin='lower', extent=[0,10,0,10])\n",
    "    title('z=%.1f  ngal=%.2f \\n smooth=%s arcmin'%(tomo_centers[i], ngal_tomo[i], theta_g))\n",
    "    colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) define the bin edges\n",
    "\n",
    "<img src=\"theory_noise_smoothed.jpg\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### the std of noise maps\n",
    "istds_noise_smoothed = array([ConvergenceMap(data=noise_maps[i], \n",
    "                                             angle=map_side_deg).smooth(theta_g*u.arcmin,mode='wrap').std() \n",
    "                            for i in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is from Coulton2019, not sure where is the log(2) factor from\n",
    "# const_n = 1/sqrt(4*log(2)*pi)#0.3388303758015525 \n",
    "\n",
    "# this matches yang2011, with their 1 arcmin = my/usual 1/sqrt(2) arcmin, and seem correct\n",
    "const_n = 1/sqrt(4*pi)\n",
    "\n",
    "## theta_g in unit of 1 arcmin, ngal in unit of 1/armin^2\n",
    "sigma_smooth = lambda ngal, theta_g: const_n* sigma_e/(theta_g * sqrt(ngal))\n",
    "sigma_n_theory = sigma_smooth (array(ngal_tomo), theta_g)\n",
    "\n",
    "print ('std for smoothed maps:')\n",
    "print (array(istds_smoothed), 'sim (white noise+kappa)')\n",
    "print (istds_noise_smoothed, 'sim (white noise)')\n",
    "print (sigma_n_theory, 'theory (white noise)')\n",
    "print (sigma_n_theory/istds_noise_smoothed, 'theory/sim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make sure smoothing is not done in place - pass\n",
    "test_map = ConvergenceMap(data=rand(4,4), angle=4*u.arcmin)\n",
    "print (test_map.data)\n",
    "smoothed_test_maps = test_map.smooth(1*u.arcmin)\n",
    "print (smoothed_test_maps.data)\n",
    "print (test_map.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_bin_edges = linspace(-5,5,21)\n",
    "print ('bin edges (sigma):\\n',sigma_bin_edges)\n",
    "\n",
    "kappa_bin_edges = kron(istds_smoothed,sigma_bin_edges).reshape(5,-1)\n",
    "#print ('bin edges (kappa):\\n', kappa_bin_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) compute peaks, minima, PDF, MFs, moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_edges = logspace(log10(40),log10(4000),21)\n",
    "ps_test = [conv_maps[i].powerSpectrum(l_edges) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    loglog(ps_test[i][0], ps_test[i][1], label='z=%s'%(tomo_centers[i]))\n",
    "xlabel('ell')\n",
    "ylabel('Clkk')\n",
    "legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_test = [smoothed_conv_maps[i].peakCount(kappa_bin_edges[i]) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_test = [smoothed_conv_maps[i].pdf(kappa_bin_edges[i]) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minima_test = [ConvergenceMap(data=-smoothed_conv_maps[i].data, \n",
    "                              angle=map_side_deg).peakCount(kappa_bin_edges[i]) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_test = [smoothed_conv_maps[i].minkowskiFunctionals(kappa_bin_edges[i]) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moments_test = [smoothed_conv_maps[i].moments(kappa_bin_edges[i]) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,axes=subplots(2,3,figsize=(14,6))\n",
    "for i in range(5):\n",
    "    axes[0][0].plot(peaks_test[i][0], peaks_test[i][1], label='z=%s'%(tomo_centers[i]))\n",
    "    axes[0][1].plot(minima_test[i][0], minima_test[i][1][::-1])## note need to flip the axis\n",
    "    axes[0][2].plot(pdf_test[i][0], pdf_test[i][1])\n",
    "    axes[1][0].plot(mf_test[i][0],mf_test[i][1])\n",
    "    axes[1][1].plot(mf_test[i][0],mf_test[i][2])\n",
    "    axes[1][2].plot(mf_test[i][0],mf_test[i][3])\n",
    "axes[0][0].legend()\n",
    "axes[1][0].set_xlabel('kappa')\n",
    "axes[1][1].set_xlabel('kappa')\n",
    "axes[1][2].set_xlabel('kappa')\n",
    "axes[0][0].set_ylabel('N_peaks')\n",
    "axes[0][1].set_ylabel('N_minima')\n",
    "axes[0][2].set_ylabel('PDF')\n",
    "axes[1][0].set_ylabel('V0')\n",
    "axes[1][1].set_ylabel('V1')\n",
    "axes[1][2].set_ylabel('V2')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) turn this into a python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float': '{: 0.5f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the std for 5 z, theta_g = 1, 5, 10\n",
    "Nbin=20\n",
    "theta_g_arr = [1,5,10]\n",
    "###### this cell takes long time to compute\n",
    "smoothed_conv_maps= [[conv_maps[i].smooth(theta_g*u.arcmin) for i in range(5)]\n",
    "                     for theta_g in theta_g_arr]\n",
    "sigma_kappa_arr = [[imap.std() for imap in maps] for maps in smoothed_conv_maps]\n",
    "savetxt('sigma_kappa.txt', sigma_kappa_arr, header='#rows=3 smoothing scales (1,5,10), cols=5 tomo bins')\n",
    "!git add sigma_kappa.txt; git commit -m 'add sigma_kappa.txt'; git push\n",
    "\n",
    "sigma_kappa_arr = genfromtxt('sigma_kappa.txt')\n",
    "\n",
    "print (array(sigma_kappa_arr).shape)\n",
    "print ('sigma_kappa for 3 smoothing, 5 tomo bins:')\n",
    "\n",
    "for isigma in sigma_kappa_arr:\n",
    "    print (isigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savetxt('ngal_tomo.txt', ngal_tomo, header='# ngal for 5 tomographic bins')\n",
    "ngal_tomo = loadtxt('ngal_tomo.txt')\n",
    "print (ngal_tomo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## galaxy noise, assuming z0_SRD, alpha_SRD = 0.11, 0.68, ngal_total=46\n",
    "# ngal_tomo = array([16.0651584 , 12.82188281,  6.9319586 ,  3.5123717 ,  1.66494164])\n",
    "\n",
    "## first set bin edges\n",
    "sigma_bin_edges = linspace(-5,5,Nbin+1)\n",
    "\n",
    "kappa_bin_edges = kron(sigma_kappa_arr,sigma_bin_edges).reshape(3,5,-1)\n",
    "print (kappa_bin_edges.shape)\n",
    "#print ('(kappa) bin edges for 3 smoothing, 5 tomo bins:\\n', kappa_bin_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dir=/global/cscratch1/sd/jialiu/desc-sprint-raytracing/Cosmo_maps/\n",
    "!ls /global/cscratch1/sd/jialiu/desc-sprint-raytracing/\n",
    "!ls /global/cscratch1/sd/jialiu/desc-sprint-raytracing/Cosmo_maps/\n",
    "!ls /global/cscratch1/sd/jialiu/desc-sprint-raytracing/Cosmo_maps/00_a/*tomo1*fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmos = [ '%02d_%s'%(i, j) for i in range(25) for j in ['a','f']]\n",
    "cosmos += ['fid_a', 'fid_f']\n",
    "cosmo_dir = '/global/cscratch1/sd/jialiu/desc-sprint-raytracing/Cosmo_maps/'\n",
    "cosmo_fn_gen = lambda cosmo, tomo, cone: cosmo_dir+cosmo+'/kappa_LSST-SRD_tomo%i_cone%i.fits'%(tomo, cone)\n",
    "\n",
    "### tomo runs from 1-5, cone run from 1-5, cosmo run from 0-24, 25 is the fiducial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### test file name geneartor: pass\n",
    "# cosmo_fn_gen(cosmos[0], 2, 3)\n",
    "# ! ls /global/cscratch1/sd/jialiu/desc-sprint-raytracing/Cosmo_maps/00_a/kappa_LSST-SRD_tomo2_cone3.fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_edges = logspace(log10(40),log10(4000),Nbin+1)\n",
    "\n",
    "sigma_e=0.26\n",
    "map_side_deg = 10*u.degree\n",
    "map_pix = 7745\n",
    "theta_g_arr = [1,5,10]\n",
    "\n",
    "pixel_angular_side = map_side_deg / map_pix\n",
    "\n",
    "sigma_pix_arr =[ (sigma_e / (pixel_angular_side * sqrt(ingal / u.arcmin**2))).decompose().value\n",
    "                for ingal in ngal_tomo]\n",
    "\n",
    "print (sigma_pix_arr)\n",
    "\n",
    "## kappa_bin_edges.shape == (3,5,21)\n",
    "def map_stats (cosmo, tomo, cone):\n",
    "    '''for fits file fn, generate ps, peaks, minima, pdf, MFs\n",
    "    fn: input file name, including full path\n",
    "    tomo=1, 2,..5: int, for tomographic bins\n",
    "    cone=1, 2,..5: int, for light cones'''\n",
    "    fn = cosmo_fn_gen(cosmo, tomo, cone)\n",
    "    imap = fits.open(fn)[0].data ## open the file\n",
    "    ### add noise\n",
    "    ### generate random see, such that it is the same for all cosmology\n",
    "    ### but different for tomo and cone\n",
    "    if cosmo[-1]=='a':\n",
    "        iseed=int(cone*100+tomo)\n",
    "    else: ##'f' starts with a different seed from the a cosmology\n",
    "        iseed=int(1000+cone*100+tomo)\n",
    "    seed(iseed)\n",
    "    noise_map = np.random.normal(loc=0.0, scale=sigma_pix_arr[tomo-1], size=(map_pix, map_pix))\n",
    "    kappa_map = ConvergenceMap(data=imap+noise_map, angle=map_side_deg)\n",
    "    \n",
    "    ### smooth the map\n",
    "    smoothed_kappa_maps= [kappa_map.smooth(theta_g*u.arcmin) for theta_g in theta_g_arr]\n",
    "    \n",
    "    out=zeros(shape=(3, 11, Nbin)) \n",
    "    # 3 smoothing, 9 cols: ell, ps, kappa, peak, minima, pdf, v0, v1, v2\n",
    "    ### compute stats\n",
    "    ps_noiseless=ConvergenceMap(data=imap, angle=map_side_deg).powerSpectrum(l_edges)\n",
    "    ps_unsmoothed=kappa_map.powerSpectrum(l_edges) ## power spectrum should be computed on unsmoothed maps\n",
    "    \n",
    "    s=0 ## smoothing scale counter\n",
    "    for imap in smoothed_kappa_maps:\n",
    "        kappa_bins = kappa_bin_edges[s][tomo-1] \n",
    "        ps=imap.powerSpectrum(l_edges)\n",
    "        peak=imap.peakCount(kappa_bins)\n",
    "        minima = ConvergenceMap(data=-imap.data, angle=map_side_deg).peakCount(kappa_bins)\n",
    "        pdf=imap.pdf(kappa_bins)\n",
    "        mfs=imap.minkowskiFunctionals(kappa_bins)\n",
    "        out[s,0] = ps[0]\n",
    "        out[s,1] = ps_noiseless[1]\n",
    "        out[s,2] = ps_unsmoothed[1]\n",
    "        out[s,3] = ps[1]\n",
    "        out[s,4] = peak[0]\n",
    "        out[s,5] = peak[1]\n",
    "        out[s,6] = minima[1][::-1]\n",
    "        out[s,7] = pdf[1]\n",
    "        out[s,8] = mfs[1]\n",
    "        out[s,9] = mfs[2]\n",
    "        out[s,10] = mfs[3]\n",
    "        s+=1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=map_stats(cosmos[-1],4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A) 124 maps for the covariance matrix out of the 800+ I plan to do, \n",
    "## B) 10 maps per cosmology out of potentially 50, and \n",
    "## C) one map per n(z) case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,axes=subplots(3,3,figsize=(14,9))\n",
    "for s in range(3):\n",
    "    axes[0][0].loglog(out[s][0],out[s][1])\n",
    "    axes[0][1].loglog(out[s][0],out[s][2])\n",
    "    axes[0][2].loglog(out[s][0],out[s][3],label='%i arcmin'%(theta_g_arr[s]))\n",
    "    axes[1][0].plot(out[s][4],out[s][5])\n",
    "    axes[1][1].plot(out[s][4],out[s][6])\n",
    "    axes[1][2].plot(out[s][4],out[s][7])\n",
    "    axes[2][0].plot(out[s][4],out[s][8])\n",
    "    axes[2][1].plot(out[s][4],out[s][9])\n",
    "    axes[2][2].plot(out[s][4],out[s][10])\n",
    "axes[0][2].legend()\n",
    "\n",
    "axes[0][0].set_xlabel('ell')\n",
    "axes[0][0].set_ylabel('clkk')\n",
    "axes[0][1].set_xlabel('ell')\n",
    "axes[0][1].set_ylabel('clkk')\n",
    "axes[0][2].set_xlabel('ell')\n",
    "axes[0][2].set_ylabel('clkk')\n",
    "\n",
    "axes[1][0].set_xlabel('kappa')\n",
    "axes[1][1].set_xlabel('kappa')\n",
    "axes[1][2].set_xlabel('kappa')\n",
    "axes[1][0].set_ylabel('N_peaks')\n",
    "axes[1][1].set_ylabel('N_minima')\n",
    "axes[1][2].set_ylabel('PDF')\n",
    "\n",
    "axes[2][0].set_xlabel('kappa')\n",
    "axes[2][1].set_xlabel('kappa')\n",
    "axes[2][2].set_xlabel('kappa')\n",
    "axes[2][0].set_ylabel('V0')\n",
    "axes[2][1].set_ylabel('V1')\n",
    "axes[2][2].set_ylabel('V2')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmo_tomo_cone_arr = [[cosmo, tomo, cone] \n",
    "                       for cosmo in cosmos \n",
    "                       for tomo in range(1,6)\n",
    "                       for cone in range(1,6)]\n",
    "print ( len(cosmo_tomo_cone_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run map_stats.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### test if sigma_e -> sigma_kappa has a sqrt(2) factor\n",
    "###### yes: sigma_kappa = sqrt(2) * sigma_e\n",
    "### KS code from: https://lenstools.readthedocs.io/en/latest/_modules/lenstools/image/shear.html?highlight=kaiser%20squire#\n",
    "\n",
    "# #Multipoles\n",
    "lx = rfftfreq(smoothed_conv_maps[1][1].data.shape[0])[None]\n",
    "ly = fftfreq(smoothed_conv_maps[1][1].data.shape[0])[:,None]\n",
    "lsquared = lx**2 + ly**2\n",
    "lsquared[0,0] = 1\n",
    "\n",
    "#FFT forward, rotation, FFT backwards\n",
    "conv_fft = rfft2(smoothed_conv_maps[1][1].data)\n",
    "s1 = irfft2((lx**2-ly**2)*conv_fft/lsquared)\n",
    "s2 = irfft2(2*lx*ly*conv_fft/lsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('kappa std', smoothed_conv_maps[1][1].std())\n",
    "print ('shear std', s1.std(), s2.std())\n",
    "print ('shear std * sqrt(2)',  sqrt(2)*s1.std(), sqrt(2)*s2.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNuJXqQkIDgS6/7DFuJ6bLq",
   "include_colab_link": true,
   "name": "prep_mass_production.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
